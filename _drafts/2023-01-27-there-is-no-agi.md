---
layout: post
title: "There Is No Such Thing as 'AGI'"
date: 2023-01-27
category: blog
byline: "An articulation of my ethos as an AI researcher"
---

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

---
In this post, I present a unique perspective on artificial intelligence (AI) that departs from the mainstream. 
I doubt it is a novel perspective, although these thoughts are all my own.

## Humans and machines as a single, cyber-physical organism

When we consider humans and machines on the timescale of natural evolution, we see a **single**, complex, cyber-physical organism rapidly moving along a noisy evolutionary landscape.
I say "rapidly" as this motion is relative to the slow evolutionary progress that, over millions of years, delivered us from our humble Worm origins.

Evolution led to homo sapiens who developed tool use. Tools expand our mental and physical faculties, making us smarter in turn. Then this allows us to make better tools, which we use to make us even smarter...surprise! We've *been* hurtling towards a singularity for some time now.

{%
    include image.html
    img="/img/AGI/energy.png"
%}

I don't think it is a hot take anymore to say that the expert systems and early AI symbolists were right (RLHF, emergence of symbols and language due to evolutionary pressures from living in communities).
We will continue to pour our knowledge into extremely complex learning systems, which we will in turn use to augment ourselves and learn how to make more powerful learning systems, *ad infinitum*.
There is a certain beauty to this cyclical, symbiotic evolutionary process, at least to me.

## There is no such thing as 'AGI'
I argue that 'AGI' is not some sentient entity made of silicon that will be announced one day in a press release by Big Tech Corp, as it is made out to be by laypersons and a surprising amount of researchers.
There is not and never will be such a thing.
Rather, what we have is an evolving symbiosis of human and machine - i use a google doc to artificially augment my intelligence and extend my short term memory. Satellites,  google translate, a chat bot helps me code faster, I use a microscope to peer at a something a nanometer long.
Think about how an alien from another solar system reacts when they see us driving a Tesla.
They will think we have exoskeletons that we can put on and take off at will. 
The futuristic imagery of a human cyborg with bionic arms and legs is misleading. 
We humans, as *generally intelligent* beings, already possess the ability to augment ourselves with *artificial* intelligences! 
Don't get me wrong---this is terribly exciting.

## What does this mean for AI Alignment?
If humans and machines are viewed as a single organism undergoing evolution, it is not obvious that we need to worry about the so-called "Alignment" of an alien "AGI" entity.
Bad humans exist, so bad cyber-physical organisms will exist! 
This is nature. 
Maybe natural evolution will eventually delete or re-write the parts of our DNA that predisposes some of us to be Evil (I'm a believer in both nurture *and* nature).

If you believe that eventually humans and machines will merge until they are indistinguishable from each other, creating something totally incomprehensible to us today, I'll listen.
I actually think this is highly plausible. 
But I would retort that this will take thousands or millions of years. 
Natural evolution hasn't even reacted yet to the invention of the steam engine.
It will not happen next year. Or in 5 years. Or in 10 years. Sorry VCs.
The outcome of this line of thinking is that it is utter nonsense to dedicate time and resources towards "building AGI" today.
In the end, natural evolution will run its course, and our job should be to just keep human civilization chugging along to be around for it.

The deep thinkers asking the hard hitting questions about how technology is/will impact the lives of people *today* are on the right track: the techno-ethicists, the anthropologists, the social scientists, and so on.
And, as AI researchers, we shouldnt be careless with making intelligent tools. War is hell. Inequity and injustice is everywhere. Try to make tools that will augment *everyone* and help them lead longer, happier, and healthier lives. 

## In conclusion
This is an articulation of my ethos as an AI researcher. I hope it inspires others in this field, helps de-hype things a bit, and keeps us focused on a goal of *empowering humans to lead better lives*.

### References

