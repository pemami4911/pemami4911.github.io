---
layout: post
title: "There Is No Such Thing as AGI: An Evolutionary Perspective"
date: 2023-01-27
category: blog
byline: "An articulation of my ethos as an AI researcher"
---

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

---
**Disclaimer**: This post contains my personal thoughts on artificial intelligence (AI) as of January 2023. I reserve the right to update my priors in light of new information as time passes. Anything written here should be taken with a grain of salt.

## Humans and machines viewed as a single, cyber-physical organism

Let's consider modern humans and machines on the same evolutionary timescale.

{%
  include image.html
  img="/img/AGI/Haeckel.png"
  caption="Tree of Vertebrates, from Ernst Haeckel's The Evolution of Man, fifth edition, London, 1910"
%}

Natural evolution lead certain animals to grow large brains and walk upright.
Then they started to develop and use tools.
These tools further expanded their mental and physical faculties, which in turn made these creatures even smarter.
Being smarter meant better tools, which again made them smarter, and eventually they developed the digital computer.

If we see tools as an extension of the self, is it a stretch to look at the *homo sapiens* branch in the tree as a *single cyber-physical* organism?

## There is no such thing as AGI
I argue that "artificial general intelligence" (AGI) is not some sentient entity forged from silicon that will be announced to the world one day in a press release by Big Tech Corp.
There is not and never will be such a thing.
Rather, what we have is an slowly evolving symbiosis of human and machine.

For example, today, I may use a Google Doc to artificially expand my short term memory while brainstorming or sitting in a meeting.
We use satellites to augment our eyes so that we can analyze vast swaths of the Earth's surface, and microscopes to peer at things a nanometer long. 
We use Google Translate to speak to people in different languages, chat bots to help us code faster...
Think about how an alien from another solar system might react if they were to see us driving a car.
They might think we have exoskeletons that we can put on and take off at will. 
 
We humans---generally intelligent beings---possess the ability to **augment** ourselves with artificial intelligences! 
The implications of this are terribly exciting.

Perhaps one might retort that "AGI" is created when humans and machines eventually merge and become completely indistinguishable from each other, creating something totally incomprehensible to us today.
I actually think this is plausible. 
But I would retort that this will take thousands or millions of years. 
Evolution hasn't even reacted yet to the invention of the steam engine.
It will not happen next year. Or in 5 years. Or in 10 years. Sorry VCs.

## Human knowledge in AI research
I don't think it is a hot take to say that from the (tiresome) symbolists vs. connectionists debate, those arguing for the fusion of both paradigms were right.
Just look at the recent success of [reinforcement learning from human feedback](https://openai.com/blog/instruction-following/), or RLHF, where human experts distill their knowledge into large language models, making them significantly better.

Like the early humans, I believe we will continue to pour our knowledge into extremely complex learning systems (i.e., modern tools), which we will in turn use to augment our faculty for creating more powerful learning systems, *ad infinitum*.
There is a certain beauty to this cyclical, symbiotic relationship, at least to me.
This back and forth, has, in fact, already kicked off one kind of singularity.

{%
    include image.html
    img="/img/AGI/energy.png"
%}



## What does this mean for AI Alignment?
If humans and machines are viewed as a single cyber-physical organism slowly exploring an evolutionary landscape, it is not obvious that we need to worry about so-called "Alignment" of some alien "AGI" entity.
Bad humans exist, and bad cyber-physical organisms will also exist! 
This is nature. 
Maybe evolution will eventually delete or re-write the parts of our DNA that predisposes some of us to be Evil (I'm a believer in both nurture *and* nature).

The outcome of this line of thinking is that it is utter nonsense to dedicate time and resources towards "building AGI" today.
In the end, natural evolution will run its course, and our job should be to just keep human civilization chugging along to be around for it.

The deep thinkers asking the hard hitting questions about how technology is/will impact the lives of people *today* are on the right track: the techno-ethicists, the anthropologists, the social scientists, and so on.
And, as AI researchers, we shouldnt be careless with making intelligent tools. War is hell. Inequity and injustice is everywhere. Try to make tools that will augment *everyone* and help them lead longer, happier, and healthier lives. 

## In conclusion
This is an articulation of my ethos as an AI researcher. I hope it inspires others in this field, helps de-hype things a bit, and keeps us focused on a goal of *empowering humans to lead better lives*.

